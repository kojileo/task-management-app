# テスト戦略ガイドライン

## 目次
1. [はじめに](#はじめに)
2. [テスト戦略の概要](#テスト戦略の概要)
3. [フロントエンドテスト戦略：テスティングトロフィー](#フロントエンドテスト戦略テスティングトロフィー)
4. [バックエンドテスト戦略：テストピラミッド](#バックエンドテスト戦略テストピラミッド)
5. [テストタイプの比較](#テストタイプの比較)
6. [各テストの詳細](#各テストの詳細)
7. [テストカバレッジ目標](#テストカバレッジ目標)
8. [テスト環境](#テスト環境)
9. [CI/CDパイプラインとの統合](#cicdパイプラインとの統合)
10. [ツールとフレームワーク](#ツールとフレームワーク)

## はじめに

本ドキュメントは、クラウドアプリの品質保証と効率的な開発スピードを確保するためのテスト戦略を定義するものです。

### 目的

- 高品質なソフトウェアの提供を確実にする
- バグの早期発見と修正を促進する
- 開発速度と品質のバランスを最適化する
- テストプロセスの標準化と透明性を確保する

## テスト戦略の概要

本ドキュメントでは、フロントエンドとバックエンドで異なるテスト戦略を採用します。これは各領域の特性と課題に最適に対応するためです。

### テスト戦略選定の根拠

フロントエンドとバックエンドでは、コードの特性、開発サイクル、テストの目的が異なるため、それぞれに最適化されたテスト戦略を採用しています。

#### フロントエンドでテスティングトロフィーを採用する理由

1. **ユーザー体験の重要性**：フロントエンドはユーザーが直接操作する部分であり、コンポーネント間の相互作用が重要です。インテグレーションテストを重視することで、ユーザー体験に直結する問題を効率的に発見できます。

2. **UI変更の頻度**：フロントエンドは頻繁に変更される傾向があり、細かすぎるユニットテストは保守コストが高くなりがちです。インテグレーションテストは変更に対する耐性が高く、より少ないテストで広範囲をカバーできます。

3. **静的解析の有効性**：TypeScriptなどの型システムやESLintなどの静的解析ツールが発達しており、多くのバグをコーディング段階で検出できます。これにより、ユニットテストの一部を代替できます。

4. **実装よりも振る舞いの重視**：フロントエンドでは内部実装よりも、ユーザーから見た振る舞いが重要です。インテグレーションテストは実装の詳細に依存せず、振る舞いに焦点を当てたテストが可能です。

#### バックエンドでテストピラミッドを採用する理由

1. **ビジネスロジックの複雑性**：バックエンドにはビジネスロジックが集中しており、細かい機能単位でのテストが重要です。ユニットテストを多く実施することで、ロジックのバグを効率的に検出できます。

2. **パフォーマンスと安定性の要求**：バックエンドはシステム全体のパフォーマンスと安定性に大きく影響します。ユニットテストは実行が高速で安定しているため、頻繁な実行に適しています。

### フロントエンドとバックエンドのテスト戦略

- **フロントエンド**：テスティングトロフィー
  - インテグレーションテストを中心に据える
  - 静的解析を基盤として重視
  - E2Eテストは厳選して少数実施

- **バックエンド**：テストピラミッド
  - ユニットテストを最大量で実施
  - 上位のテストほど数を減らす
  - 実行速度と安定性を重視

## フロントエンドテスト戦略：テスティングトロフィー

フロントエンドでは、テスティングトロフィー（Testing Trophy）を採用します。このテスト戦略は、フロントエンドのコードにおけるユーザーフローを意識した一連の画面・機能連携のテスト価値と各種コストのバランスを考慮し、静的解析を基盤とし、インテグレーションテストに重点を置くアプローチです。

```
    🏆
   / \      - E2Eテスト（20%）
  /   \
 /     \    - インテグレーションテスト（50%）
/       \
---------    - ユニットテスト（30%）
\_______/    - 静的解析（基盤）
```

### E2Eテスト選定基準

E2Eテストはコストが高いため、以下の基準に基づいて厳選して実施します：

1. **ビジネスクリティカルなフロー**：
   - ユーザー登録・ログインフロー
   - 決済・購入フロー
   - 主要な契約・申込みフロー

2. **複雑な状態管理を含むフロー**：
   - 複数ステップのウィザード
   - ユーザー間のインタラクション
   - 複雑なフォーム入力と検証

3. **外部システム連携**：
   - 決済ゲートウェイとの連携
   - 外部APIとの重要な連携ポイント
   - ファイルアップロード/ダウンロード機能

4. **パフォーマンス懸念がある領域**：
   - 大量データの表示や処理
   - 頻繁なAPIコールを伴う操作

5. **定期的な回帰テスト**：
   - 過去に重大な障害が発生した機能
   - 頻繁に変更が加えられる機能

各四半期ごとにE2Eテスト対象を見直し、テストの有効性と実行コストのバランスを最適化します。

## バックエンドテスト戦略：テストピラミッド

バックエンドでは、Martin Fowlerが推奨するテストピラミッド（Test Pyramid）モデルを採用します。このモデルは、実行速度と安定性を考慮し、ユニットテストを基盤として多数実装し、上位のテストほど数を減らすアプローチです。

```
      /\      - APIテスト（30%）
     /  \
    /    \    
   /      \
  /        \
 /          \
 ------------   - ユニットテスト（70%）
```

### バックエンドのインテグレーションテストとAPIテストの関係

バックエンドでは、インテグレーションテストとAPIテストを以下のように区別し、関連付けます：

1. **インテグレーションテストの位置づけ**：
   - バックエンドのインテグレーションテストは、複数のコンポーネント（サービス、リポジトリ、外部システムなど）が連携して動作することを検証するテストです。
   - これらのテストはAPIテストの一部として実施し、APIエンドポイントを通じて複数のコンポーネントの連携を検証します。

2. **APIテストの範囲**：
   - 単一のAPIエンドポイントのテスト（入力検証、レスポンス形式、エラーハンドリングなど）
   - 複数のAPIエンドポイントを組み合わせたフロー検証（≒インテグレーションテスト）
   - 外部システム連携のテスト（モックを使用）

3. **実施アプローチ**：
   - ユニットテスト：個々のサービスメソッドやビジネスロジックを分離してテスト
   - APIテスト：RESTful APIエンドポイントを通じて、サービス間の連携やデータフローをテスト

このように、バックエンドではAPIテストが従来のインテグレーションテストの役割を一部担い、効率的なテスト戦略を実現します。

## テストタイプの比較

フロントエンドとバックエンドにおける各テストレベルの特性と違いを以下の表で比較します。


| テストタイプ | フロントエンド | バックエンド | 
|------------|--------------|------------|
| **静的解析** | • コードの書き方の問題を自動検出<br>• タイプミスや構文エラーをチェック<br>• 利用しているOSSの脆弱性をチェック<br>• 脆弱なコードをチェック | • コードの書き方の問題を自動検出<br>• タイプミスや構文エラーをチェック<br>• 利用しているOSSの脆弱性をチェック<br>• 脆弱なコードをチェック |
| **ユニットテスト** | • コンポーネントが正しく表示できるか確認<br>• ボタンクリックなどの反応を確認<br>•外部関数との連携はモックを活用 | • 個別の処理機能が正しく動くか確認<br>• ビジネスロジックが想定通りか確認<br>•外部関数との連携はモックを活用 |
| **インテグレーションテスト** | • 複数コンポーネントの連携を確認<br>• フォームの入力から送信までの流れを確認<br>• APIのモックとの連携を確認 ||
| **APIテスト** | | • エンドポイントの機能確認<br>• リクエストバリデーション<br>• レスポンス形式の確認<br>• エラーハンドリングの確認<br>• 認証/認可の確認 |
| **E2Eテスト** | • 実際のブラウザでの操作を確認<br>• 画面からサーバーまでの連携を確認<br>• 一括処理の全体実行を確認<br>• 外部システムとの実際の連携を確認 | |

### テストの実行特性比較

各テストタイプの実行特性を比較します。

| 特性 | 静的解析 | ユニットテスト | インテグレーションテスト+APIテスト | E2Eテスト |
|-----|---------|-------------|-------------------|---------|
| **実行速度** | ◎超高速（数ミリ秒） | 〇とても速い（1秒以内） | △普通（数秒〜数十秒） | ×遅い（数十秒〜数分） |
| **安定性** | ◎完全に安定 | 〇とても安定している | △比較的安定している | ×不安定になりやすい |
| **作成コストの低さ** | ◎自動生成可能 | ×困難 | △やや困難 | 〇簡単 |
| **保守の手間** | ◎ほとんど不要 | 〇少ない | △普通 | ×多い |
| **見つかるバグ** | コード品質の問題<br>セキュリティの問題<br>パフォーマンスの問題 | 個別画面・機能の問題 | ユーザー目線の画面・機能連携の問題 | クリティカルなユーザーフローの問題 |
| **実行タイミング** | PR作成時 | PR作成時 | PR作成時 | 評価環境デプロイ時 |

## 各テストの詳細

### 静的解析

**定義**：
コードを実行せずに、コードの品質、セキュリティ、パフォーマンスの問題を検出するテスト。

**目的**：
- コードの品質問題を早期に発見
- セキュリティリスクの事前検出
- パフォーマンスボトルネックの特定
- コーディング規約の遵守確認

**実施方法**：
- リンター（ESLint, StyleCop）によるコード解析
- セキュリティスキャナー（Snyk）による脆弱性チェック
- コードフォーマッター（Prettier）による一貫性確保

### ユニットテスト

**定義**：
単一の機能単位（関数、メソッド、コンポーネント）を分離してテストするもの。外部依存性は可能な限りモック/スタブする。

**目的**：
- 個々のコード単位が期待通りに動作することを確認
- コードの変更による影響を迅速に検出
- 開発者のフィードバックループを短縮

**フロントエンドの例**：
- ユーティリティ関数のテスト
- 単一のReactコンポーネントのレンダリングテスト
- イベントハンドラの動作確認

**バックエンドの例**：
- 個々のサービスメソッドのテスト
- データ変換ロジックのテスト
- バリデーションロジックのテスト

**モックの効果的な使用**：

モックは外部依存性を分離し、テストの信頼性と再現性を高めるために使用します。以下のガイドラインに従ってモックを活用します：

1. **モック対象の明確化**：
   - 外部API呼び出し
   - データベースアクセス
   - ファイルシステム操作
   - 時間依存のロジック
   - 外部サービスとの連携

2. **フロントエンドでのモック**：
   - APIリクエストは `jest.mock` または `msw` を使用
   - コンテキストやReduxストアは浅いモックで代替
   - ブラウザAPIは `jest-environment-jsdom` で模倣
   - イベントハンドラは `jest.fn()` でスパイ

3. **バックエンドでのモック**：
   - リポジトリ層はインメモリ実装で代替
   - 外部APIは `Moq` などでモック
   - データベースは特定のテスト用インスタンスや `in-memory-db` を使用

4. **モックの粒度**：
   - 単一の関数やメソッドはスタブまたはスパイで対応
   - 複雑なサービスは部分的にモック
   - 外部システム全体はモックサーバーで代替

5. **モックの避けるべきケース**：
   - テスト対象のコア機能そのもの
   - 純粋関数（副作用のない関数）
   - 単純なデータ構造

### インテグレーションテスト

**定義**：
複数のコンポーネントや機能が連携して正しく動作するかを検証するテスト。

**目的**：
- コンポーネント間の連携が期待通りに動作することを確認
- ユーザー体験に直結する機能の整合性を検証
- 開発者のフィードバックループを短縮

**フロントエンドの例**：
- フォーム入力と送信の一連の流れ
- APIモックを使用したデータフェッチングのテスト
- 複数コンポーネントの連携動作確認

**フロントエンドのAPI連携モック手法**：

1. **MSW (Mock Service Worker)の活用**：
   - ブラウザとサーバー両方で一貫したモック
   - 実際のネットワークリクエストをインターセプト
   - リアルなAPIレスポンスをシミュレート

2. **テストデータの準備**：
   - 成功・失敗両方のレスポンスを用意
   - エッジケース（空配列、大量データなど）を考慮
   - レスポンス遅延のシミュレート

3. **テストケース設計**：
   - データ取得中のローディング状態確認
   - エラー発生時のフォールバックUI確認
   - 再試行機能のテスト
   - キャッシュ機能のテスト

4. **実装例**：
   ```javascript
   // MSW設定例
   import { rest } from 'msw';
   import { setupServer } from 'msw/node';

   const server = setupServer(
     rest.get('/api/users', (req, res, ctx) => {
       return res(ctx.json([{ id: 1, name: 'Test User' }]));
     }),
     rest.post('/api/login', (req, res, ctx) => {
       return res(ctx.status(200), ctx.json({ token: 'test-token' }));
     })
   );

   beforeAll(() => server.listen());
   afterEach(() => server.resetHandlers());
   afterAll(() => server.close());
   ```

### APIテスト

**定義**：
APIのエンドポイントが期待通りに動作するかを検証するテスト。

**目的**：
- APIの機能が仕様通りに動作することを確認
- リクエスト/レスポンスの形式が正しいことを確認
- エラーハンドリングが適切に行われることを確認

**バックエンドの例**：
- エンドポイントの機能確認
- リクエストバリデーション
- レスポンス形式の確認
- エラーハンドリングの確認
- 認証/認可の確認
- パフォーマンスの確認

### E2Eテスト

**定義**：
実際のクラウド環境で、ブラウザを起動しシステム全体の動作を検証するテスト。

**目的**：
- エンドユーザーの視点からシステムの機能を検証
- クリティカルなユーザーフローが正常に動作することを確認
- 本番環境に近い条件でのシステムの動作を検証

**実施項目**：
- ログイン〜商品購入までの一連のフロー
- 実際のブラウザを使用したナビゲーションのテスト
- フォーム入力からバックエンドまでの完全なデータフロー
- 外部システムとの連携確認

## テストカバレッジ目標

テストタイプごとのカバレッジ目標例を表形式で記載。

### フロントエンドとバックエンドのテストカバレッジ目標

| コンポーネント | テストタイプ | ラインカバレッジ目標 | 分岐カバレッジ目標 | 主な対象 |
|------------|----------|--------------|--------------|-------|
| **フロントエンド<br>コア機能** | ユニットテスト | 80% | 70% | • ステート管理ロジック<br>• ユーティリティ関数<br>• バリデーション<br>• API呼び出し、データ処理関数 |
| **フロントエンド<br>UI** | ユニットテスト | 70% | 60% | • コンポーネントのレンダリング<br>• イベントハンドラ<br>• 条件付き表示<br>• スタイル制御ロジック |
| **フロントエンド** | インテグレーションテスト | - | - | • API呼び出し部分を網羅的に実施|
| **バックエンド<br>ビジネスロジック** | ユニットテスト | 90% | 80% | • ドメインロジック<br>• サービスロジック<br>• 計算処理<br>• バリデーション |
| **バックエンド** | APIテスト | - | - | • API呼び出しを網羅的に実施 |

## テスト環境

テスト実行環境を明確に定義し、各環境の目的と特性を以下に記載します。

### 環境の種類と目的

| 環境 | 主な目的 | 特性 | 主なテストタイプ |
|-----|---------|------|--------------|
| **ローカル開発環境** | 開発者の個人作業環境 | • 開発者のPC上<br>• 即時フィードバック<br>• モックを多用 | • 静的解析<br>• ユニットテスト<br>• インテグレーションテスト |
| **CI環境** | 自動テスト実行環境 | • クラウド上の一時環境<br>• PR毎に生成・破棄<br>• 独立性の確保 | • 静的解析<br>• ユニットテスト<br>• インテグレーションテスト<br>• APIテスト |
| **テスト環境** | 結合テスト用環境 | • 安定したクラウド環境<br>• 本番に近いインフラ<br>• テスト用データセット | • E2Eテスト<br>• 手動テスト<br> |
| **本番環境** | サービス提供環境 | • 実ユーザーが使用 ||

## CI/CDパイプラインとの統合

### パイプラインにおけるテスト実行順序

1. 静的解析（PR作成時）
   - コード品質チェック
   - セキュリティスキャン
   - パフォーマンス分析

2. ユニットテスト（PR作成時）
   - フロントエンドコンポーネントテスト
   - バックエンドビジネスロジックテスト
   - コードカバレッジ確認

3. インテグレーションテスト+APIテスト（PR作成時）
   - フロントエンド：コンポーネント間連携テスト
   - バックエンド：APIエンドポイントテスト
   - リクエスト/レスポンス形式確認

4. E2Eテスト（デプロイ後）
   - クリティカルパスの動作確認
   - 外部システム連携確認
   - パフォーマンス検証

### 品質ゲート

| ステージ | 品質ゲート条件 | 実施タイミング |
|---------|-------------|------------|
| PR作成 | • 静的解析パス<br>• ユニットテスト100%パス<br>• コードカバレッジ閾値達成<br>• インテグレーションテストパス<br>• APIテストパス | PR作成時 |
| デプロイ（テスト環境） | • 自動E2Eテストパス<br>  • 手動E2Eテストパス<br>| デプロイ前 |
| デプロイ（本番環境） | | デプロイ前 |

## ツールとフレームワーク

### フロントエンド

- **静的解析**: ESLint, Prettier, Snyk
- **ユニットテスト**: Jest
- **インテグレーションテスト**: Jest, React Testing Library
- **E2Eテスト**: Playwright

### バックエンド

- **静的解析**: StyleCop, Snyk
- **ユニットテスト**: XUnit
- **APIテスト**: Postman